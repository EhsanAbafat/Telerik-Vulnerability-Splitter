#!/usr/bin/env python3

# By Ehsan Abafat
# https://abafat.ir
# Usage: You need 2 files in the root first file is old url.txt and last one is clean url.txt
# put the URLs that need be clean in fist file and run the "python source.py" command
# open the clean url.txt and boom! it is finished!
# Short Usage: Python3 source.py

import time
import sys
import re
from tqdm.auto import tqdm
import requests
from bs4 import BeautifulSoup
# from colorama import Fore, Back, Style

try:
    def finish():
        print("""

        ==============================

        Duplicated URLs Remover With it Fathers!

           => ~ Developed Version ~ 1.0.4 ==[Beta]== By Ehsan Abafat
         _____ _                          _    _            __       _
        | ____| |__  ___  __ _ _ __      / \  | |__   __ _ / _| __ _| |_
        |  _| | '_ \/ __|/ _` | '_ \    / _ \ | '_ \ / _` | |_ / _` | __|
        | |___| | | \__ \ (_| | | | |  / ___ \| |_) | (_| |  _| (_| | |_
        |_____|_| |_|___/\__,_|_| |_| /_/   \_\_.__/ \__,_|_|  \__,_|\__|

        =============================

        clean URLs successfully!

        time that spent for this proccess:

        """)
        print(toc - tic, "S")

    if sys.argv[1] == '-h':
        print(100*"*")
        print('''

            => ~ Usage : Put dirty URLs in "old url.txt" file and call python3 source.py -?

                    -s : Fully Clean URLs
                    -d : Clean URLs with keeping "/"
                    -f : Clean Duplicated URLs Example : 1 2 3 2 => 1 2 3

           => ~ Developed Version ~ 1.0.4 ==[Beta]== By Ehsan Abafat

        ''')
        print(100*"*")
    elif sys.argv[1] == '-s':

        tic = time.time()
        f = open("old url.txt", "r")
        flisted = f.read().lower().replace('https', 'http').replace(
            'http://', '').replace('www.', '')
        SmartRemover = re.sub("/(\w+)?", "", flisted).split('\n')
        listurl = []
        dupurl = ["\n"]
        fullclean = []
        print('\n Getting Lines... \n')
        for i in tqdm(SmartRemover):
            if i in listurl:
                dupurl.append(i.strip())
            else:
                listurl.append(i.strip())
        print('\n Cleaning... \n')
        for i in tqdm(listurl):
            if i not in dupurl:
                fullclean.append(i)
        f.close()

        flast = open("clean url.txt", "w")
        for i in fullclean:
            if(i != '\n' and i != '\s' and i != '' and len(i) > 2):
                flast.write('http://'+str(i)+'\n')
        toc = time.time()
        finish()
        flast.close()
    elif sys.argv[1] == '-d':

        tic = time.time()
        f = open("old url.txt", "r")
        flisted = f.read().lower().replace('https', 'http').replace(
            'http://', '').replace('www.', '').split()
        listurl = []
        dupurl = ["\n"]
        fullclean = []
        print('\n Getting Lines... \n')
        for i in tqdm(flisted):
            if i in listurl:
                dupurl.append(i.strip())
            else:
                listurl.append(i.strip())
        print('\n Cleaning... \n')
        for i in tqdm(listurl):
            if i not in dupurl:
                fullclean.append(i)
        f.close()

        flast = open("clean url.txt", "w")
        for i in fullclean:
            if(i != '\n' and i != '\s' and i != '' and len(i) > 2):
                flast.write('http://'+str(i)+'\n')
        toc = time.time()
        finish()
        flast.close()
    elif sys.argv[1] == '-f':

        tic = time.time()
        f = open("old url.txt", "r")
        flisted = f.read().lower().replace('https', 'http').replace(
            'http://', '').replace('www.', '').split()
        listurl = []
        dupurl = ["\n"]
        fullclean = []
        print('\n Getting Lines... \n')
        for i in tqdm(flisted):
            if i in listurl:
                dupurl.append(i.strip())
            else:
                listurl.append(i.strip())
        print('\n Cleaning... \n')
        flast = open("clean url.txt", "w")
        for i in tqdm(listurl):
            print(i)
            if(i != '\n' and i != '\s' and i != '' and len(i) > 2):
                flast.write('http://'+str(i)+'\n')
        f.close()

        toc = time.time()
        finish()
        flast.close()
    else:
        print('unknown command! use python3 source.py -h')

    if len(sys.argv) == 2:
        pass
    elif len(sys.argv) == 3 and sys.argv[2] == '--s':
        telerikuiVul = '{ "message" : "RadAsyncUpload handler is registered succesfully, however, it may not be accessed directly." }'
        telerikBugCheckADR = "/Telerik.Web.UI.WebResource.axd?type=rau"
        fopen2 = open("clean url.txt", "r")
        splurl = fopen2.read().split('\n')
        vullist = []
        for i in tqdm(splurl):
            try:
                getthis = requests.get(i, allow_redirects=True)
                sop = BeautifulSoup(getthis.text, 'html.parser')
                if "http-equiv=\"refresh\"" in str(sop) or 'http-equiv=\'refresh\'' in str(sop):
                    URLREfMet = re.search(
                    "(http://|https://)(\w{3}\.)?([\w]+\.[\w]+[\.\w]+[\/\w]+)", str(sop))
                    vullist.append(URLREfMet.group(0))
                else:
                    vullist.append(getthis.url)
            except Exception as e:
                print(i+" has error!!! :)")
        fopen2.close()
        vulss = []
        for i in vullist:
            addr = i + telerikBugCheckADR
            print(addr)
            reqbug = requests.get(str(addr))
            BugFound = BeautifulSoup(reqbug.text, 'html.parser')
            if telerikuiVul in BugFound:
                vulss.append(i)
            else:
                pass
        print(vulss)
        fopen3 = open("vul list.txt", "w")

        for i in vulss:
            fopen3.write(str(i)+"\n")
    else:
        if(sys.argv[1] != '-h'):
            print("use '<Python3 source.py -h>' command")
        else:
            print('You are see Usage of This Script!')

except Exception as e:
    print(e)
